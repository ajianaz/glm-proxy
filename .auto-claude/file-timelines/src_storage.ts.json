{
  "file_path": "src/storage.ts",
  "main_branch_history": [],
  "task_views": {
    "006-implement-in-memory-api-key-cache-with-ttl-to-elim": {
      "task_id": "006-implement-in-memory-api-key-cache-with-ttl-to-elim",
      "branch_point": {
        "commit_hash": "e4ccb2c239067a08687940247e7dc3c37228e546",
        "content": "import fs from 'fs';\nimport path from 'path';\nimport type { ApiKeysData, ApiKey } from './types.js';\n\nconst DATA_FILE = process.env.DATA_FILE || path.join(process.cwd(), 'data/apikeys.json');\nconst LOCK_FILE = DATA_FILE + '.lock';\n\n// Ensure data directory exists\nconst DATA_DIR = path.dirname(DATA_FILE);\nif (!fs.existsSync(DATA_DIR)) {\n  fs.mkdirSync(DATA_DIR, { recursive: true });\n}\n\n// Simple file lock using mkdir (atomic on Unix)\nexport async function withLock<T>(fn: () => Promise<T>): Promise<T> {\n  const maxRetries = 10;\n  const retryDelay = 50;\n\n  for (let i = 0; i < maxRetries; i++) {\n    try {\n      fs.mkdirSync(LOCK_FILE, { mode: 0o755 });\n      break;\n    } catch (e: unknown) {\n      if ((e as NodeJS.ErrnoException).code !== 'EEXIST' || i === maxRetries - 1) throw e;\n      await new Promise(r => setTimeout(r, retryDelay));\n    }\n  }\n\n  try {\n    return await fn();\n  } finally {\n    fs.rmdirSync(LOCK_FILE);\n  }\n}\n\nexport async function readApiKeys(): Promise<ApiKeysData> {\n  try {\n    const content = await fs.promises.readFile(DATA_FILE, 'utf-8');\n    return JSON.parse(content);\n  } catch {\n    return { keys: [] };\n  }\n}\n\nexport async function writeApiKeys(data: ApiKeysData): Promise<void> {\n  const tempFile = DATA_FILE + '.tmp';\n  await fs.promises.writeFile(tempFile, JSON.stringify(data, null, 2), 'utf-8');\n  await fs.promises.rename(tempFile, DATA_FILE);\n}\n\nexport async function findApiKey(key: string): Promise<ApiKey | null> {\n  return await withLock(async () => {\n    const data = await readApiKeys();\n    return data.keys.find(k => k.key === key) || null;\n  });\n}\n\nexport async function updateApiKeyUsage(\n  key: string,\n  tokensUsed: number,\n  _model: string\n): Promise<void> {\n  await withLock(async () => {\n    const data = await readApiKeys();\n    const keyIndex = data.keys.findIndex(k => k.key === key);\n\n    if (keyIndex === -1) return;\n\n    const apiKey = data.keys[keyIndex];\n    const now = new Date().toISOString();\n\n    // Update last_used and total tokens\n    apiKey.last_used = now;\n    apiKey.total_lifetime_tokens += tokensUsed;\n\n    // Find or create current window\n    const fiveHoursAgo = new Date(Date.now() - 5 * 60 * 60 * 1000).toISOString();\n    let currentWindow = apiKey.usage_windows.find(\n      w => w.window_start >= fiveHoursAgo\n    );\n\n    if (!currentWindow) {\n      currentWindow = { window_start: now, tokens_used: 0 };\n      apiKey.usage_windows.push(currentWindow);\n    }\n\n    currentWindow.tokens_used += tokensUsed;\n\n    // Clean up old windows\n    apiKey.usage_windows = apiKey.usage_windows.filter(\n      w => w.window_start >= fiveHoursAgo\n    );\n\n    await writeApiKeys(data);\n  });\n}\n\nexport async function getKeyStats(key: string): Promise<ApiKey | null> {\n  return await findApiKey(key);\n}\n",
        "timestamp": "2026-01-22T13:20:55.122162"
      },
      "worktree_state": {
        "content": "import fs from 'fs';\nimport path from 'path';\nimport type { ApiKeysData, ApiKey } from './types.js';\nimport { apiKeyCache } from './cache.js';\n\n// Helper function to check if cache is enabled (reads env var at runtime)\nfunction isCacheEnabled(): boolean {\n  return process.env.CACHE_ENABLED !== 'false';\n}\n\n// Cache logging configuration\nconst CACHE_LOG_LEVEL = process.env.CACHE_LOG_LEVEL || 'none';\n\n/**\n * Simple logger for cache operations\n * Logs are only output if the level is <= CACHE_LOG_LEVEL\n * Levels: none < info < debug\n */\nfunction logCache(level: 'info' | 'debug', message: string, meta?: Record<string, unknown>): void {\n  if (CACHE_LOG_LEVEL === 'none') {\n    return;\n  }\n\n  if (level === 'debug' && CACHE_LOG_LEVEL !== 'debug') {\n    return;\n  }\n\n  const timestamp = new Date().toISOString();\n  const logEntry = {\n    timestamp,\n    level,\n    message,\n    ...meta,\n  };\n\n  if (level === 'debug') {\n    console.log(`[cache] ${message}`, meta ? JSON.stringify(meta) : '');\n  } else {\n    console.log(`[cache] ${message}`, meta ? JSON.stringify(meta) : '');\n  }\n}\n\nconst DATA_FILE = process.env.DATA_FILE || path.join(process.cwd(), 'data/apikeys.json');\nconst LOCK_FILE = DATA_FILE + '.lock';\n\n// Ensure data directory exists\nconst DATA_DIR = path.dirname(DATA_FILE);\nif (!fs.existsSync(DATA_DIR)) {\n  fs.mkdirSync(DATA_DIR, { recursive: true });\n}\n\n// Simple file lock using mkdir (atomic on Unix)\nexport async function withLock<T>(fn: () => Promise<T>): Promise<T> {\n  const maxRetries = 10;\n  const retryDelay = 50;\n\n  for (let i = 0; i < maxRetries; i++) {\n    try {\n      fs.mkdirSync(LOCK_FILE, { mode: 0o755 });\n      break;\n    } catch (e: unknown) {\n      if ((e as NodeJS.ErrnoException).code !== 'EEXIST' || i === maxRetries - 1) throw e;\n      await new Promise(r => setTimeout(r, retryDelay));\n    }\n  }\n\n  try {\n    return await fn();\n  } finally {\n    fs.rmdirSync(LOCK_FILE);\n  }\n}\n\nexport async function readApiKeys(): Promise<ApiKeysData> {\n  try {\n    const content = await fs.promises.readFile(DATA_FILE, 'utf-8');\n    return JSON.parse(content);\n  } catch {\n    return { keys: [] };\n  }\n}\n\nexport async function writeApiKeys(data: ApiKeysData): Promise<void> {\n  const tempFile = DATA_FILE + '.tmp';\n  await fs.promises.writeFile(tempFile, JSON.stringify(data, null, 2), 'utf-8');\n  await fs.promises.rename(tempFile, DATA_FILE);\n}\n\nexport async function findApiKey(key: string): Promise<ApiKey | null> {\n  // Check cache first if enabled\n  if (isCacheEnabled()) {\n    // Use has() to check if key exists in cache (distinguishes miss from cached null)\n    if (apiKeyCache.has(key)) {\n      // Key exists in cache, retrieve it (may be null for not-found keys)\n      const cached = apiKeyCache.get(key);\n\n      // Debug log cache hit\n      logCache('debug', 'Cache hit', {\n        key: key.substring(0, 8) + '...', // Partial key for security\n        found: cached !== null,\n      });\n\n      return cached;\n    }\n\n    // Debug log cache miss\n    logCache('debug', 'Cache miss - fallback to file', {\n      key: key.substring(0, 8) + '...',\n    });\n  }\n\n  // Cache miss or disabled - fall back to file read\n  return await withLock(async () => {\n    const data = await readApiKeys();\n    const apiKey = data.keys.find(k => k.key === key) || null;\n\n    // Populate cache for future requests (including null for not-found keys)\n    if (isCacheEnabled()) {\n      apiKeyCache.set(key, apiKey);\n\n      // Debug log cache population\n      logCache('debug', 'Cache populated after file read', {\n        key: key.substring(0, 8) + '...',\n        found: apiKey !== null,\n      });\n    }\n\n    return apiKey;\n  });\n}\n\nexport async function updateApiKeyUsage(\n  key: string,\n  tokensUsed: number,\n  _model: string\n): Promise<void> {\n  await withLock(async () => {\n    const data = await readApiKeys();\n    const keyIndex = data.keys.findIndex(k => k.key === key);\n\n    if (keyIndex === -1) return;\n\n    const apiKey = data.keys[keyIndex];\n    const now = new Date().toISOString();\n\n    // Update last_used and total tokens\n    apiKey.last_used = now;\n    apiKey.total_lifetime_tokens += tokensUsed;\n\n    // Find or create current window\n    const fiveHoursAgo = new Date(Date.now() - 5 * 60 * 60 * 1000).toISOString();\n    let currentWindow = apiKey.usage_windows.find(\n      w => w.window_start >= fiveHoursAgo\n    );\n\n    if (!currentWindow) {\n      currentWindow = { window_start: now, tokens_used: 0 };\n      apiKey.usage_windows.push(currentWindow);\n    }\n\n    currentWindow.tokens_used += tokensUsed;\n\n    // Clean up old windows\n    apiKey.usage_windows = apiKey.usage_windows.filter(\n      w => w.window_start >= fiveHoursAgo\n    );\n\n    await writeApiKeys(data);\n\n    // Update cache with modified API key to maintain coherency\n    if (isCacheEnabled()) {\n      apiKeyCache.set(key, apiKey);\n\n      // Info log cache invalidation/update\n      logCache('info', 'Cache updated after usage update', {\n        key: key.substring(0, 8) + '...',\n        tokensUsed,\n        totalTokens: apiKey.total_lifetime_tokens,\n      });\n    }\n  });\n}\n\nexport async function getKeyStats(key: string): Promise<ApiKey | null> {\n  return await findApiKey(key);\n}\n\n/**\n * Warm up the cache by loading all API keys into memory.\n * This is optional and should be called on application startup if enabled.\n * Runs asynchronously and doesn't block the startup process.\n */\nexport async function warmupCache(): Promise<void> {\n  if (!isCacheEnabled()) {\n    return;\n  }\n\n  try {\n    // Read all API keys from storage\n    const data = await withLock(async () => {\n      return await readApiKeys();\n    });\n\n    // Populate cache with all keys\n    let loaded = 0;\n    for (const apiKey of data.keys) {\n      apiKeyCache.set(apiKey.key, apiKey);\n      loaded++;\n    }\n\n    // Log warm-up completion\n    const stats = apiKeyCache.getStats();\n    logCache('info', 'Cache warm-up completed', {\n      keysLoaded: loaded,\n      cacheSize: stats.size,\n      maxSize: stats.maxSize,\n    });\n  } catch (error) {\n    // Don't fail startup if warm-up fails, just log the error\n    console.error('Cache warm-up failed:', error);\n  }\n}\n",
        "last_modified": "2026-01-22T13:20:55.580343"
      },
      "task_intent": {
        "title": "Implement in-memory API key cache with TTL to eliminate file I/O on every request",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-22T12:46:07.654477",
  "last_updated": "2026-01-22T13:20:55.456515"
}