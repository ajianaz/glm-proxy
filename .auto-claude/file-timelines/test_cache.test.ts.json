{
  "file_path": "test/cache.test.ts",
  "main_branch_history": [],
  "task_views": {
    "006-implement-in-memory-api-key-cache-with-ttl-to-elim": {
      "task_id": "006-implement-in-memory-api-key-cache-with-ttl-to-elim",
      "branch_point": {
        "commit_hash": "e4ccb2c239067a08687940247e7dc3c37228e546",
        "content": "",
        "timestamp": "2026-01-22T13:20:55.122162"
      },
      "worktree_state": {
        "content": "import { describe, it, expect, beforeEach, vi } from 'vitest';\nimport { LRUCacheImpl, LRUCache, CacheStats } from '../src/cache.js';\n\ndescribe('LRUCache', () => {\n  let cache: LRUCache<string>;\n\n  beforeEach(() => {\n    cache = new LRUCacheImpl<string>(3, 100); // maxSize: 3, TTL: 100ms for testing\n  });\n\n  describe('Basic get/set operations', () => {\n    it('should set and get a value', () => {\n      cache.set('key1', 'value1');\n      expect(cache.get('key1')).toBe('value1');\n    });\n\n    it('should return null for non-existent key', () => {\n      expect(cache.get('nonexistent')).toBeNull();\n    });\n\n    it('should update existing key', () => {\n      cache.set('key1', 'value1');\n      cache.set('key1', 'value2');\n      expect(cache.get('key1')).toBe('value2');\n      expect(cache.size).toBe(1);\n    });\n\n    it('should store null values', () => {\n      cache.set('key1', null);\n      expect(cache.get('key1')).toBeNull();\n      expect(cache.has('key1')).toBe(true);\n    });\n\n    it('should return correct size', () => {\n      expect(cache.size).toBe(0);\n      cache.set('key1', 'value1');\n      expect(cache.size).toBe(1);\n      cache.set('key2', 'value2');\n      expect(cache.size).toBe(2);\n    });\n\n    it('should return correct maxSize', () => {\n      expect(cache.maxSize).toBe(3);\n    });\n  });\n\n  describe('TTL expiration', () => {\n    it('should return value before TTL expires', () => {\n      cache.set('key1', 'value1', 100);\n      expect(cache.get('key1')).toBe('value1');\n    });\n\n    it('should return null after TTL expires', async () => {\n      cache.set('key1', 'value1', 50); // 50ms TTL\n      await new Promise(resolve => setTimeout(resolve, 60)); // Wait for expiration\n      expect(cache.get('key1')).toBeNull();\n    });\n\n    it('should remove expired entries from cache', async () => {\n      cache.set('key1', 'value1', 50);\n      expect(cache.size).toBe(1);\n      await new Promise(resolve => setTimeout(resolve, 60));\n      cache.get('key1'); // Trigger expiration check\n      expect(cache.size).toBe(0);\n    });\n\n    it('should count expired entries as cache misses', async () => {\n      cache.set('key1', 'value1', 50);\n      await new Promise(resolve => setTimeout(resolve, 60));\n      cache.get('key1'); // Expired, should be a miss\n      const stats = cache.getStats();\n      expect(stats.misses).toBe(1);\n      expect(stats.hits).toBe(0);\n    });\n\n    it('should use default TTL when not specified', async () => {\n      const defaultCache = new LRUCacheImpl<string>(10, 50); // 50ms default TTL\n      defaultCache.set('key1', 'value1');\n      await new Promise(resolve => setTimeout(resolve, 60));\n      expect(defaultCache.get('key1')).toBeNull();\n    });\n\n    it('should allow custom TTL override', async () => {\n      const defaultCache = new LRUCacheImpl<string>(10, 50); // 50ms default TTL\n      defaultCache.set('key1', 'value1', 200); // 200ms custom TTL\n      await new Promise(resolve => setTimeout(resolve, 60));\n      expect(defaultCache.get('key1')).toBe('value1'); // Should still be valid\n    });\n  });\n\n  describe('LRU eviction', () => {\n    it('should evict least recently used entry when cache is full', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n      expect(cache.size).toBe(3);\n\n      // This should evict key1 (least recently used)\n      cache.set('key4', 'value4');\n      expect(cache.size).toBe(3);\n      expect(cache.get('key1')).toBeNull(); // key1 was evicted\n      expect(cache.get('key2')).toBe('value2');\n      expect(cache.get('key3')).toBe('value3');\n      expect(cache.get('key4')).toBe('value4');\n    });\n\n    it('should update LRU order on get', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      // Access key1 to make it more recently used\n      cache.get('key1');\n\n      // Add key4, should evict key2 (now least recently used)\n      cache.set('key4', 'value4');\n      expect(cache.get('key2')).toBeNull(); // key2 was evicted\n      expect(cache.get('key1')).toBe('value1'); // key1 still exists\n      expect(cache.get('key3')).toBe('value3');\n      expect(cache.get('key4')).toBe('value4');\n    });\n\n    it('should update LRU order on set', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      // Update key1 to make it more recently used\n      cache.set('key1', 'value1-updated');\n\n      // Add key4, should evict key2 (now least recently used)\n      cache.set('key4', 'value4');\n      expect(cache.get('key2')).toBeNull(); // key2 was evicted\n      expect(cache.get('key1')).toBe('value1-updated'); // key1 still exists\n      expect(cache.get('key3')).toBe('value3');\n      expect(cache.get('key4')).toBe('value4');\n    });\n\n    it('should handle eviction correctly with repeated access', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      // Access key1 and key2 multiple times\n      cache.get('key1');\n      cache.get('key2');\n      cache.get('key1');\n\n      // Add key4, should evict key3\n      cache.set('key4', 'value4');\n      expect(cache.get('key3')).toBeNull(); // key3 was evicted\n      expect(cache.get('key1')).toBe('value1');\n      expect(cache.get('key2')).toBe('value2');\n      expect(cache.get('key4')).toBe('value4');\n    });\n  });\n\n  describe('Cache statistics tracking', () => {\n    beforeEach(() => {\n      cache = new LRUCacheImpl<string>(10, 100);\n    });\n\n    it('should track cache hits', () => {\n      cache.set('key1', 'value1');\n      cache.get('key1'); // Hit\n      cache.get('key1'); // Hit\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(2);\n      expect(stats.misses).toBe(0);\n    });\n\n    it('should track cache misses', () => {\n      cache.get('nonexistent1'); // Miss\n      cache.get('nonexistent2'); // Miss\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(0);\n      expect(stats.misses).toBe(2);\n    });\n\n    it('should calculate hit rate correctly', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n\n      cache.get('key1'); // Hit\n      cache.get('key2'); // Hit\n      cache.get('nonexistent'); // Miss\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(2);\n      expect(stats.misses).toBe(1);\n      expect(stats.hitRate).toBeCloseTo(66.67, 1);\n    });\n\n    it('should return 0% hit rate when no operations', () => {\n      const stats = cache.getStats();\n      expect(stats.hitRate).toBe(0);\n    });\n\n    it('should track size in statistics', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n\n      const stats = cache.getStats();\n      expect(stats.size).toBe(2);\n      expect(stats.maxSize).toBe(10);\n    });\n\n    it('should reset statistics', () => {\n      cache.set('key1', 'value1');\n      cache.get('key1'); // Hit\n      cache.get('nonexistent'); // Miss\n\n      cache.resetStats();\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(0);\n      expect(stats.misses).toBe(0);\n      expect(stats.hitRate).toBe(0);\n      expect(stats.size).toBe(1); // Size should remain\n    });\n\n    it('should track expired entries as misses', async () => {\n      cache.set('key1', 'value1', 50);\n      await new Promise(resolve => setTimeout(resolve, 60));\n      cache.get('key1'); // Expired = miss\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(0);\n      expect(stats.misses).toBe(1);\n    });\n  });\n\n  describe('has operation', () => {\n    it('should return true for existing key', () => {\n      cache.set('key1', 'value1');\n      expect(cache.has('key1')).toBe(true);\n    });\n\n    it('should return false for non-existent key', () => {\n      expect(cache.has('nonexistent')).toBe(false);\n    });\n\n    it('should return false for expired entries', async () => {\n      cache.set('key1', 'value1', 50);\n      await new Promise(resolve => setTimeout(resolve, 60));\n      expect(cache.has('key1')).toBe(false);\n    });\n\n    it('should not update LRU order', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      cache.has('key1'); // Should not update LRU order\n\n      // Add key4, should evict key1 (least recently used, has() didn't update order)\n      cache.set('key4', 'value4');\n      expect(cache.get('key1')).toBeNull(); // key1 was evicted (was least recently used)\n      expect(cache.get('key2')).toBe('value2');\n    });\n  });\n\n  describe('delete operation', () => {\n    it('should delete existing key', () => {\n      cache.set('key1', 'value1');\n      cache.delete('key1');\n      expect(cache.get('key1')).toBeNull();\n      expect(cache.has('key1')).toBe(false);\n      expect(cache.size).toBe(0);\n    });\n\n    it('should be no-op for non-existent key', () => {\n      cache.delete('nonexistent');\n      expect(cache.size).toBe(0);\n    });\n\n    it('should handle deleting from middle of cache', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      cache.delete('key2');\n      expect(cache.size).toBe(2);\n      expect(cache.has('key2')).toBe(false);\n      expect(cache.has('key1')).toBe(true);\n      expect(cache.has('key3')).toBe(true);\n    });\n\n    it('should handle deleting oldest entry', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      cache.delete('key1');\n      expect(cache.size).toBe(2);\n      expect(cache.get('key1')).toBeNull();\n    });\n\n    it('should handle deleting newest entry', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      cache.delete('key3');\n      expect(cache.size).toBe(2);\n      expect(cache.get('key3')).toBeNull();\n    });\n  });\n\n  describe('clear operation', () => {\n    it('should clear all entries', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      cache.clear();\n\n      expect(cache.size).toBe(0);\n      expect(cache.get('key1')).toBeNull();\n      expect(cache.get('key2')).toBeNull();\n      expect(cache.get('key3')).toBeNull();\n    });\n\n    it('should preserve statistics after clear', () => {\n      cache.set('key1', 'value1');\n      cache.get('key1'); // Hit\n      cache.get('nonexistent'); // Miss\n\n      cache.clear();\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(1);\n      expect(stats.misses).toBe(1);\n      expect(cache.size).toBe(0);\n    });\n\n    it('should allow adding entries after clear', () => {\n      cache.set('key1', 'value1');\n      cache.clear();\n      expect(cache.size).toBe(0);\n\n      cache.set('key2', 'value2');\n      expect(cache.size).toBe(1);\n      expect(cache.get('key2')).toBe('value2');\n    });\n  });\n\n  describe('Edge cases', () => {\n    it('should handle empty cache', () => {\n      expect(cache.size).toBe(0);\n      expect(cache.get('key1')).toBeNull();\n      expect(cache.has('key1')).toBe(false);\n    });\n\n    it('should handle duplicate keys', () => {\n      cache.set('key1', 'value1');\n      cache.set('key1', 'value2');\n      cache.set('key1', 'value3');\n\n      expect(cache.get('key1')).toBe('value3');\n      expect(cache.size).toBe(1);\n    });\n\n    it('should handle special characters in keys', () => {\n      const largeCache = new LRUCacheImpl<string>(10, 100);\n\n      largeCache.set('key with spaces', 'value1');\n      largeCache.set('key-with-dashes', 'value2');\n      largeCache.set('key_with_underscores', 'value3');\n      largeCache.set('key.with.dots', 'value4');\n\n      expect(largeCache.get('key with spaces')).toBe('value1');\n      expect(largeCache.get('key-with-dashes')).toBe('value2');\n      expect(largeCache.get('key_with_underscores')).toBe('value3');\n      expect(largeCache.get('key.with.dots')).toBe('value4');\n    });\n\n    it('should handle empty string as key', () => {\n      cache.set('', 'empty-key-value');\n      expect(cache.get('')).toBe('empty-key-value');\n    });\n\n    it('should handle very long keys', () => {\n      const longKey = 'a'.repeat(1000);\n      cache.set(longKey, 'value');\n      expect(cache.get(longKey)).toBe('value');\n    });\n\n    it('should handle null values correctly', () => {\n      cache.set('key1', null);\n      expect(cache.get('key1')).toBeNull();\n      expect(cache.has('key1')).toBe(true);\n\n      // Distinguish between null value and missing key\n      expect(cache.get('nonexistent')).toBeNull();\n      expect(cache.has('nonexistent')).toBe(false);\n    });\n\n    it('should handle updating value from non-null to null', () => {\n      cache.set('key1', 'value1');\n      cache.set('key1', null);\n      expect(cache.get('key1')).toBeNull();\n      expect(cache.has('key1')).toBe(true);\n    });\n\n    it('should handle updating value from null to non-null', () => {\n      cache.set('key1', null);\n      cache.set('key1', 'value1');\n      expect(cache.get('key1')).toBe('value1');\n    });\n\n    it('should handle cache with maxSize of 1', () => {\n      const smallCache = new LRUCacheImpl<string>(1, 100);\n\n      smallCache.set('key1', 'value1');\n      expect(smallCache.size).toBe(1);\n      expect(smallCache.get('key1')).toBe('value1');\n\n      smallCache.set('key2', 'value2');\n      expect(smallCache.size).toBe(1);\n      expect(smallCache.get('key1')).toBeNull(); // Evicted\n      expect(smallCache.get('key2')).toBe('value2');\n    });\n\n    it('should handle very large maxSize', () => {\n      const largeCache = new LRUCacheImpl<string>(10000, 100);\n\n      for (let i = 0; i < 1000; i++) {\n        largeCache.set(`key${i}`, `value${i}`);\n      }\n\n      expect(largeCache.size).toBe(1000);\n      expect(largeCache.get('key0')).toBe('value0');\n      expect(largeCache.get('key999')).toBe('value999');\n    });\n  });\n\n  describe('Concurrent access simulation', () => {\n    it('should handle rapid set operations', () => {\n      for (let i = 0; i < 100; i++) {\n        cache.set(`key${i % 3}`, `value${i}`); // Only 3 keys due to maxSize\n      }\n\n      expect(cache.size).toBe(3);\n      expect(cache.has('key0')).toBe(true);\n      expect(cache.has('key1')).toBe(true);\n      expect(cache.has('key2')).toBe(true);\n    });\n\n    it('should handle rapid get operations', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n\n      for (let i = 0; i < 100; i++) {\n        cache.get('key1');\n        cache.get('key2');\n      }\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(200);\n      expect(stats.misses).toBe(0);\n    });\n\n    it('should handle interleaved operations', () => {\n      cache.set('key1', 'value1');\n      cache.get('key1'); // Hit\n      cache.get('key2'); // Miss (doesn't exist yet)\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n      cache.delete('key1');\n      cache.set('key4', 'value4'); // Should add without eviction (size is 2 after delete)\n\n      expect(cache.size).toBe(3);\n      expect(cache.has('key1')).toBe(false);\n      expect(cache.has('key2')).toBe(true);\n      expect(cache.has('key3')).toBe(true);\n      expect(cache.has('key4')).toBe(true);\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(1);\n      expect(stats.misses).toBe(1);\n    });\n  });\n\n  describe('Statistics accuracy', () => {\n    it('should maintain accurate statistics across all operations', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n\n      cache.get('key1'); // Hit (1)\n      cache.get('key2'); // Hit (2)\n      cache.get('key3'); // Miss (1)\n\n      cache.has('key1'); // No stats change\n      cache.has('key4'); // No stats change\n\n      cache.set('key3', 'value3');\n      cache.get('key3'); // Hit (3)\n\n      cache.delete('key1'); // No stats change\n      cache.get('key1'); // Miss (2)\n\n      cache.clear(); // No stats reset\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(3);\n      expect(stats.misses).toBe(2);\n      expect(stats.hitRate).toBe(60);\n      expect(stats.size).toBe(0);\n    });\n\n    it('should track LRU eviction without affecting stats', () => {\n      cache.set('key1', 'value1');\n      cache.set('key2', 'value2');\n      cache.set('key3', 'value3');\n\n      cache.get('key1'); // Hit (1)\n      cache.get('key2'); // Hit (2)\n\n      cache.set('key4', 'value4'); // Evicts key3\n\n      cache.get('key3'); // Miss (1) - evicted\n      cache.get('key4'); // Hit (3)\n\n      const stats = cache.getStats();\n      expect(stats.hits).toBe(3);\n      expect(stats.misses).toBe(1);\n    });\n  });\n\n  describe('TTL edge cases', () => {\n    it('should handle zero TTL', async () => {\n      cache.set('key1', 'value1', 0);\n      await new Promise(resolve => setTimeout(resolve, 10));\n      expect(cache.get('key1')).toBeNull(); // Should expire immediately\n    });\n\n    it('should handle very short TTL', async () => {\n      cache.set('key1', 'value1', 1); // 1ms TTL\n      await new Promise(resolve => setTimeout(resolve, 10));\n      expect(cache.get('key1')).toBeNull();\n    });\n\n    it('should handle very long TTL', () => {\n      cache.set('key1', 'value1', 999999999); // Very long TTL\n      expect(cache.get('key1')).toBe('value1');\n    });\n\n    it('should refresh TTL on update', async () => {\n      cache.set('key1', 'value1', 50);\n      await new Promise(resolve => setTimeout(resolve, 30));\n\n      cache.set('key1', 'value1-updated', 100); // Refresh TTL\n      await new Promise(resolve => setTimeout(resolve, 30));\n\n      // Original TTL would have expired, but updated one is still valid\n      expect(cache.get('key1')).toBe('value1-updated');\n    });\n  });\n\n  describe('Real-world scenarios', () => {\n    it('should simulate API key caching pattern', () => {\n      // Simulate API keys\n      const apiKey1 = { key: 'pk_1', name: 'User1', model: 'glm-4.7' };\n      const apiKey2 = { key: 'pk_2', name: 'User2', model: 'glm-4' };\n\n      const apiCache = new LRUCacheImpl<typeof apiKey1>(10, 5000);\n\n      // First request - cache miss\n      let result = apiCache.get('pk_1');\n      expect(result).toBeNull();\n\n      // Populate cache\n      apiCache.set('pk_1', apiKey1);\n      apiCache.set('pk_2', apiKey2);\n\n      // Subsequent requests - cache hits\n      result = apiCache.get('pk_1');\n      expect(result).toEqual(apiKey1);\n\n      result = apiCache.get('pk_2');\n      expect(result).toEqual(apiKey2);\n\n      const stats = apiCache.getStats();\n      expect(stats.hits).toBe(2);\n      expect(stats.misses).toBe(1);\n      expect(stats.hitRate).toBeCloseTo(66.67, 1);\n    });\n\n    it('should simulate negative caching for invalid keys', () => {\n      const invalidKeyCache = new LRUCacheImpl<string | null>(10, 5000);\n\n      // Cache negative result (key not found)\n      invalidKeyCache.set('pk_invalid', null);\n\n      // Check - should find it (to avoid repeated disk lookups)\n      expect(invalidKeyCache.has('pk_invalid')).toBe(true);\n      expect(invalidKeyCache.get('pk_invalid')).toBeNull();\n\n      // Distinguish from truly non-existent key\n      expect(invalidKeyCache.has('pk_another_invalid')).toBe(false);\n    });\n\n    it('should handle cache warm-up scenario', () => {\n      const warmCache = new LRUCacheImpl<string>(100, 5000);\n\n      // Simulate loading many keys at startup\n      for (let i = 0; i < 50; i++) {\n        warmCache.set(`pk_${i}`, `key_data_${i}`);\n      }\n\n      expect(warmCache.size).toBe(50);\n      expect(warmCache.get('pk_0')).toBe('key_data_0');\n      expect(warmCache.get('pk_49')).toBe('key_data_49');\n    });\n  });\n});\n",
        "last_modified": "2026-01-22T13:20:55.584329"
      },
      "task_intent": {
        "title": "Implement in-memory API key cache with TTL to eliminate file I/O on every request",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-22T12:46:07.693393",
  "last_updated": "2026-01-22T13:20:55.501706"
}