{
  "file_path": "src/proxy.ts",
  "main_branch_history": [],
  "task_views": {
    "006-implement-in-memory-api-key-cache-with-ttl-to-elim": {
      "task_id": "006-implement-in-memory-api-key-cache-with-ttl-to-elim",
      "branch_point": {
        "commit_hash": "e4ccb2c239067a08687940247e7dc3c37228e546",
        "content": "import type { ApiKey } from './types.js';\nimport { getModelForKey } from './validator.js';\nimport { updateApiKeyUsage } from './storage.js';\n\nconst ZAI_API_BASE = 'https://api.z.ai/api/coding/paas/v4';\nconst ZAI_API_KEY = process.env.ZAI_API_KEY;\n\nexport interface ProxyOptions {\n  apiKey: ApiKey;\n  path: string;\n  method: string;\n  headers: Record<string, string>;\n  body: string | null;\n}\n\nexport interface ProxyResult {\n  success: boolean;\n  status: number;\n  headers: Record<string, string>;\n  body: string;\n  tokensUsed?: number;\n}\n\nexport async function proxyRequest(options: ProxyOptions): Promise<ProxyResult> {\n  const { apiKey, path, method, headers, body } = options;\n\n  // Runtime check for ZAI_API_KEY\n  if (!ZAI_API_KEY) {\n    return {\n      success: false,\n      status: 500,\n      headers: { 'content-type': 'application/json' },\n      body: JSON.stringify({\n        error: {\n          message: 'ZAI_API_KEY environment variable is not configured',\n          type: 'configuration_error',\n        },\n      }),\n      tokensUsed: 0,\n    };\n  }\n\n  const model = getModelForKey(apiKey);\n\n  // Build target URL\n  // Z.AI uses /v4 base, OpenAI compatibility but without /v1 prefix\n  // e.g., /v1/chat/completions -> /chat/completions -> /v4/chat/completions\n  const cleanPath = path.startsWith('/v1/') ? path.substring(4) : path;\n  const slash = cleanPath.startsWith('/') ? '' : '/';\n  const targetUrl = `${ZAI_API_BASE}${slash}${cleanPath}`;\n\n  // Prepare headers for Z.AI - always forward Authorization with master key\n  const proxyHeaders: Record<string, string> = {\n    'Authorization': `Bearer ${ZAI_API_KEY}`,\n  };\n\n  // Forward relevant headers from client (but not Authorization)\n  const forwardHeaders = ['content-type', 'accept', 'user-agent'];\n  for (const h of forwardHeaders) {\n    const key = Object.keys(headers).find(k => k.toLowerCase() === h);\n    if (key) {\n      proxyHeaders[key] = headers[key];\n    }\n  }\n\n  // Inject/override model in request body\n  let processedBody = body;\n  let tokensUsed = 0;\n\n  if (body && (method === 'POST' || method === 'PUT' || method === 'PATCH')) {\n    try {\n      const bodyJson = JSON.parse(body);\n\n      // Inject model for chat/completions endpoint\n      if (path.includes('/chat/completions') || path.includes('/completions')) {\n        bodyJson.model = model;\n      }\n\n      processedBody = JSON.stringify(bodyJson);\n    } catch {\n      // Body not JSON, leave as-is\n    }\n  }\n\n  // Make request to Z.AI\n  try {\n    const response = await fetch(targetUrl, {\n      method,\n      headers: proxyHeaders,\n      body: processedBody,\n    });\n\n    // Get response body\n    const responseBody = await response.text();\n\n    // Extract token usage from response\n    if (response.ok) {\n      try {\n        const responseJson = JSON.parse(responseBody);\n\n        // OpenAI format usage\n        if (responseJson.usage) {\n          tokensUsed = responseJson.usage.total_tokens || 0;\n        }\n\n        // Update usage after successful request\n        if (tokensUsed > 0) {\n          // Don't await - fire and forget for performance\n          updateApiKeyUsage(apiKey.key, tokensUsed, model).catch(console.error);\n        }\n      } catch {\n        // Response not JSON or no usage field\n      }\n    }\n\n    // Build response headers\n    const responseHeaders: Record<string, string> = {\n      'content-type': response.headers.get('content-type') || 'application/json',\n    };\n\n    return {\n      success: response.ok,\n      status: response.status,\n      headers: responseHeaders,\n      body: responseBody,\n      tokensUsed,\n    };\n  } catch (error: any) {\n    return {\n      success: false,\n      status: 502,\n      headers: { 'content-type': 'application/json' },\n      body: JSON.stringify({\n        error: {\n          message: `Upstream request failed: ${error.message}`,\n          type: 'upstream_error',\n        },\n      }),\n      tokensUsed: 0,\n    };\n  }\n}\n",
        "timestamp": "2026-01-22T13:20:55.122162"
      },
      "worktree_state": {
        "content": "import type { ApiKey } from './types.js';\nimport { getModelForKey } from './validator.js';\nimport { updateApiKeyUsage } from './storage.js';\n\nconst ZAI_API_BASE = 'https://api.z.ai/api/coding/paas/v4';\n\nfunction getZaiApiKey(): string | undefined {\n  return process.env.ZAI_API_KEY;\n}\n\nexport interface ProxyOptions {\n  apiKey: ApiKey;\n  path: string;\n  method: string;\n  headers: Record<string, string>;\n  body: string | null;\n}\n\nexport interface ProxyResult {\n  success: boolean;\n  status: number;\n  headers: Record<string, string>;\n  body: string;\n  tokensUsed?: number;\n}\n\nexport async function proxyRequest(options: ProxyOptions): Promise<ProxyResult> {\n  const { apiKey, path, method, headers, body } = options;\n\n  // Runtime check for ZAI_API_KEY\n  const ZAI_API_KEY = getZaiApiKey();\n  if (!ZAI_API_KEY) {\n    return {\n      success: false,\n      status: 500,\n      headers: { 'content-type': 'application/json' },\n      body: JSON.stringify({\n        error: {\n          message: 'ZAI_API_KEY environment variable is not configured',\n          type: 'configuration_error',\n        },\n      }),\n      tokensUsed: 0,\n    };\n  }\n\n  const model = getModelForKey(apiKey);\n\n  // Build target URL\n  // Z.AI uses /v4 base, OpenAI compatibility but without /v1 prefix\n  // e.g., /v1/chat/completions -> /chat/completions -> /v4/chat/completions\n  const cleanPath = path.startsWith('/v1/') ? path.substring(4) : path;\n  const slash = cleanPath.startsWith('/') ? '' : '/';\n  const targetUrl = `${ZAI_API_BASE}${slash}${cleanPath}`;\n\n  // Prepare headers for Z.AI - always forward Authorization with master key\n  const proxyHeaders: Record<string, string> = {\n    'Authorization': `Bearer ${ZAI_API_KEY}`,\n  };\n\n  // Forward relevant headers from client (but not Authorization)\n  const forwardHeaders = ['content-type', 'accept', 'user-agent'];\n  for (const h of forwardHeaders) {\n    const key = Object.keys(headers).find(k => k.toLowerCase() === h);\n    if (key) {\n      proxyHeaders[key] = headers[key];\n    }\n  }\n\n  // Inject/override model in request body\n  let processedBody = body;\n  let tokensUsed = 0;\n\n  if (body && (method === 'POST' || method === 'PUT' || method === 'PATCH')) {\n    try {\n      const bodyJson = JSON.parse(body);\n\n      // Inject model for chat/completions endpoint\n      if (path.includes('/chat/completions') || path.includes('/completions')) {\n        bodyJson.model = model;\n      }\n\n      processedBody = JSON.stringify(bodyJson);\n    } catch {\n      // Body not JSON, leave as-is\n    }\n  }\n\n  // Make request to Z.AI\n  try {\n    const response = await fetch(targetUrl, {\n      method,\n      headers: proxyHeaders,\n      body: processedBody,\n    });\n\n    // Get response body\n    const responseBody = await response.text();\n\n    // Extract token usage from response\n    if (response.ok) {\n      try {\n        const responseJson = JSON.parse(responseBody);\n\n        // OpenAI format usage\n        if (responseJson.usage) {\n          tokensUsed = responseJson.usage.total_tokens || 0;\n        }\n\n        // Update usage after successful request\n        if (tokensUsed > 0) {\n          // Don't await - fire and forget for performance\n          updateApiKeyUsage(apiKey.key, tokensUsed, model).catch(console.error);\n        }\n      } catch {\n        // Response not JSON or no usage field\n      }\n    }\n\n    // Build response headers\n    const responseHeaders: Record<string, string> = {\n      'content-type': response.headers.get('content-type') || 'application/json',\n    };\n\n    return {\n      success: response.ok,\n      status: response.status,\n      headers: responseHeaders,\n      body: responseBody,\n      tokensUsed,\n    };\n  } catch (error: any) {\n    return {\n      success: false,\n      status: 502,\n      headers: { 'content-type': 'application/json' },\n      body: JSON.stringify({\n        error: {\n          message: `Upstream request failed: ${error.message}`,\n          type: 'upstream_error',\n        },\n      }),\n      tokensUsed: 0,\n    };\n  }\n}\n",
        "last_modified": "2026-01-22T13:20:55.579539"
      },
      "task_intent": {
        "title": "Implement in-memory API key cache with TTL to eliminate file I/O on every request",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-22T12:46:07.645999",
  "last_updated": "2026-01-22T13:20:55.446322"
}