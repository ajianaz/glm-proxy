{
  "file_path": "test/cache-failure-scenarios.test.ts",
  "main_branch_history": [],
  "task_views": {
    "006-implement-in-memory-api-key-cache-with-ttl-to-elim": {
      "task_id": "006-implement-in-memory-api-key-cache-with-ttl-to-elim",
      "branch_point": {
        "commit_hash": "e4ccb2c239067a08687940247e7dc3c37228e546",
        "content": "",
        "timestamp": "2026-01-22T13:20:55.122162"
      },
      "worktree_state": {
        "content": "import { describe, it, expect, beforeEach, afterAll } from 'vitest';\nimport { readApiKeys, writeApiKeys, findApiKey, updateApiKeyUsage, warmupCache } from '../src/storage.js';\nimport { apiKeyCache } from '../src/cache.js';\nimport { existsSync, unlinkSync, readFileSync, writeFileSync } from 'fs';\nimport { join } from 'path';\n\n// Mock DATA_FILE environment variable for tests\nconst TEST_FILE = join(process.cwd(), 'data', 'test-failure-scenarios.json');\n\n// Save original DATA_FILE and CACHE_ENABLED\nconst originalDataFile = process.env.DATA_FILE;\nconst originalCacheEnabled = process.env.CACHE_ENABLED;\nconst originalCacheLogLevel = process.env.CACHE_LOG_LEVEL;\n\nconst testApiKey = {\n  key: 'pk_test_failure',\n  name: 'Test Failure Scenarios',\n  model: 'glm-4.7',\n  token_limit_per_5h: 100000,\n  expiry_date: '2026-12-31T23:59:59Z',\n  created_at: '2026-01-18T00:00:00Z',\n  last_used: '2026-01-18T00:00:00Z',\n  total_lifetime_tokens: 0,\n  usage_windows: [],\n};\n\ndescribe('Cache Failure Scenarios and Edge Cases', () => {\n  const ACTUAL_FILE = join(process.cwd(), 'data', 'apikeys.json');\n\n  beforeEach(() => {\n    // Set test data file\n    process.env.DATA_FILE = TEST_FILE;\n    process.env.CACHE_ENABLED = 'true';\n    process.env.CACHE_LOG_LEVEL = 'none'; // Suppress logs during tests\n\n    // Clean up both test file and actual file before each test\n    if (existsSync(TEST_FILE)) {\n      unlinkSync(TEST_FILE);\n    }\n    if (existsSync(ACTUAL_FILE)) {\n      unlinkSync(ACTUAL_FILE);\n    }\n\n    // Clear cache and reset stats before each test\n    apiKeyCache.clear();\n    apiKeyCache.resetStats();\n  });\n\n  afterAll(() => {\n    // Restore original environment variables\n    process.env.DATA_FILE = originalDataFile;\n    process.env.CACHE_ENABLED = originalCacheEnabled;\n    process.env.CACHE_LOG_LEVEL = originalCacheLogLevel;\n\n    // Clean up test file\n    if (existsSync(TEST_FILE)) {\n      unlinkSync(TEST_FILE);\n    }\n  });\n\n  describe('Graceful degradation on file read errors', () => {\n    it('should handle missing file gracefully', async () => {\n      // Ensure file doesn't exist\n      if (existsSync(TEST_FILE)) {\n        unlinkSync(TEST_FILE);\n      }\n\n      // First call should handle missing file and return null\n      const result1 = await findApiKey('pk_nonexistent');\n      expect(result1).toBeNull();\n\n      // Verify null was cached (negative caching)\n      const stats = apiKeyCache.getStats();\n      expect(stats.size).toBe(1);\n      expect(apiKeyCache.has('pk_nonexistent')).toBe(true);\n\n      // Second call should hit cache with null\n      apiKeyCache.resetStats();\n      const result2 = await findApiKey('pk_nonexistent');\n      expect(result2).toBeNull();\n\n      // Verify cache was hit (no file read)\n      const stats2 = apiKeyCache.getStats();\n      expect(stats2.hits).toBe(1);\n      expect(stats2.misses).toBe(0);\n    });\n\n    it('should handle corrupted JSON file gracefully', async () => {\n      // Write invalid JSON to file\n      writeFileSync(TEST_FILE, '{ invalid json }', 'utf-8');\n\n      // findApiKey should handle the error gracefully via readApiKeys\n      // readApiKeys catches errors and returns { keys: [] }\n      const result = await findApiKey('pk_any_key');\n      expect(result).toBeNull();\n    });\n\n    it('should handle cache clear and repopulation', async () => {\n      // Write valid API key file\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // First call populates cache\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1).toEqual(testApiKey);\n\n      // Verify cache was populated\n      expect(apiKeyCache.size).toBe(1);\n\n      // Clear cache manually\n      apiKeyCache.clear();\n\n      // Cache should be empty\n      expect(apiKeyCache.size).toBe(0);\n\n      // Next call should repopulate from file\n      const result2 = await findApiKey(testApiKey.key);\n      expect(result2).toEqual(testApiKey);\n\n      // Cache should be populated again\n      expect(apiKeyCache.size).toBe(1);\n    });\n\n    it('should handle concurrent requests without errors', async () => {\n      // Write valid API key file\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Make several concurrent requests (not too many to avoid lock contention)\n      const requests = Array.from({ length: 10 }, () =>\n        findApiKey(testApiKey.key)\n      );\n\n      // All requests should succeed without errors\n      const results = await Promise.all(requests);\n      expect(results).toHaveLength(10);\n      results.forEach(result => {\n        expect(result).not.toBeNull();\n        expect(result?.key).toBe(testApiKey.key);\n      });\n\n      // Cache should have been populated\n      expect(apiKeyCache.size).toBe(1);\n    });\n  });\n\n  describe('TTL expiration behavior', () => {\n    it('should cache entries with proper TTL', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // First call populates cache\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1).not.toBeNull();\n\n      const stats1 = apiKeyCache.getStats();\n      expect(stats1.size).toBe(1);\n\n      // Verify entry exists in cache\n      expect(apiKeyCache.has(testApiKey.key)).toBe(true);\n\n      // Retrieve from cache\n      const cached = apiKeyCache.get(testApiKey.key);\n      expect(cached).not.toBeNull();\n      expect(cached?.key).toBe(testApiKey.key);\n    });\n\n    it('should handle rapid cache misses and hits', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Clear cache\n      apiKeyCache.clear();\n      apiKeyCache.resetStats();\n\n      // First call is a miss and populates cache\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1).not.toBeNull();\n\n      // Reset stats to measure subsequent hits\n      apiKeyCache.resetStats();\n\n      // Next 10 calls should all be hits\n      for (let i = 0; i < 10; i++) {\n        const result = await findApiKey(testApiKey.key);\n        expect(result).not.toBeNull();\n      }\n\n      const stats = apiKeyCache.getStats();\n      expect(stats.hits).toBe(10);\n      expect(stats.misses).toBe(0);\n      expect(stats.hitRate).toBe(100);\n    });\n\n    it('should repopulate cache after entry is deleted', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Clear cache\n      apiKeyCache.clear();\n\n      // First call should populate cache\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1).not.toBeNull();\n      expect(apiKeyCache.has(testApiKey.key)).toBe(true);\n\n      // Simulate cache expiration by clearing the entry\n      apiKeyCache.delete(testApiKey.key);\n      expect(apiKeyCache.has(testApiKey.key)).toBe(false);\n\n      // Next call should repopulate cache from file\n      const result2 = await findApiKey(testApiKey.key);\n      expect(result2).not.toBeNull();\n      expect(apiKeyCache.has(testApiKey.key)).toBe(true);\n    });\n  });\n\n  describe('File update coherency', () => {\n    it('should update cache when file is modified', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // First call populates cache\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1?.total_lifetime_tokens).toBe(0);\n\n      // Update usage (writes to file and updates cache)\n      await updateApiKeyUsage(testApiKey.key, 1000, 'glm-4.7');\n\n      // Cache should be updated immediately\n      const result2 = await findApiKey(testApiKey.key);\n      expect(result2?.total_lifetime_tokens).toBe(1000);\n\n      // Verify the file was also updated by reading it directly\n      const fileData = await readApiKeys();\n      const fileKey = fileData.keys.find((k: { key: string }) => k.key === testApiKey.key);\n      expect(fileKey?.total_lifetime_tokens).toBe(1000);\n\n      // Verify cache hit (no file read)\n      const stats = apiKeyCache.getStats();\n      expect(stats.hits).toBeGreaterThan(0);\n    });\n\n    it('should handle multiple updates correctly', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Initial cache population\n      await findApiKey(testApiKey.key);\n\n      // Make multiple updates\n      await updateApiKeyUsage(testApiKey.key, 100, 'glm-4.7');\n      await updateApiKeyUsage(testApiKey.key, 200, 'glm-4.7');\n      await updateApiKeyUsage(testApiKey.key, 300, 'glm-4.7');\n\n      // Final value should be sum of all updates\n      const result = await findApiKey(testApiKey.key);\n      expect(result?.total_lifetime_tokens).toBe(600); // 100+200+300\n\n      // Verify file consistency by reading via storage layer\n      const fileData = await readApiKeys();\n      const fileKey = fileData.keys.find((k: { key: string }) => k.key === testApiKey.key);\n      expect(fileKey?.total_lifetime_tokens).toBe(600);\n    });\n\n    it('should maintain cache coherency with selective updates', async () => {\n      const key2 = {\n        ...testApiKey,\n        key: 'pk_test_2',\n        name: 'Test Key 2',\n      };\n\n      await writeApiKeys({ keys: [testApiKey, key2] });\n\n      // Populate cache with both keys\n      await findApiKey(testApiKey.key);\n      await findApiKey(key2.key);\n\n      expect(apiKeyCache.size).toBe(2);\n\n      // Update only first key\n      await updateApiKeyUsage(testApiKey.key, 1000, 'glm-4.7');\n\n      // First key should be updated\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1?.total_lifetime_tokens).toBe(1000);\n\n      // Second key should be unchanged\n      const result2 = await findApiKey(key2.key);\n      expect(result2?.total_lifetime_tokens).toBe(0);\n\n      // Both should still be in cache\n      expect(apiKeyCache.size).toBe(2);\n    });\n\n    it('should serve fresh data after file is externally modified', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Initial cache population\n      await findApiKey(testApiKey.key);\n\n      // Externally modify the file (simulate another process updating it)\n      const updatedKey = {\n        ...testApiKey,\n        total_lifetime_tokens: 5000,\n      };\n      await writeApiKeys({ keys: [updatedKey] });\n\n      // Clear cache entry to simulate cache invalidation\n      apiKeyCache.delete(testApiKey.key);\n\n      // Next read should fetch fresh data from file\n      const result = await findApiKey(testApiKey.key);\n      expect(result?.total_lifetime_tokens).toBe(5000);\n\n      // Verify it's in cache now\n      expect(apiKeyCache.has(testApiKey.key)).toBe(true);\n    });\n  });\n\n  describe('Startup with empty cache', () => {\n    it('should start correctly with empty cache', async () => {\n      // Verify cache is empty\n      expect(apiKeyCache.size).toBe(0);\n\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // First request should work and populate cache\n      const result = await findApiKey(testApiKey.key);\n      expect(result).not.toBeNull();\n      expect(result?.key).toBe(testApiKey.key);\n\n      // Cache should now have the key\n      expect(apiKeyCache.size).toBe(1);\n    });\n\n    it('should handle cache warm-up with empty file', async () => {\n      // Create empty file\n      await writeApiKeys({ keys: [] });\n\n      // Warm-up should not throw\n      await warmupCache();\n\n      // Cache should remain empty\n      expect(apiKeyCache.size).toBe(0);\n    });\n\n    it('should handle cache warm-up with missing file', async () => {\n      // Ensure file doesn't exist\n      if (existsSync(TEST_FILE)) {\n        unlinkSync(TEST_FILE);\n      }\n\n      // Warm-up should not throw\n      await warmupCache();\n\n      // Cache should remain empty\n      expect(apiKeyCache.size).toBe(0);\n    });\n\n    it('should populate cache during warm-up', async () => {\n      const key2 = {\n        ...testApiKey,\n        key: 'pk_warmup_2',\n        name: 'Warmup Key 2',\n      };\n\n      await writeApiKeys({ keys: [testApiKey, key2] });\n\n      // Clear cache\n      apiKeyCache.clear();\n\n      // Run warm-up\n      await warmupCache();\n\n      // Cache should have both keys\n      expect(apiKeyCache.size).toBe(2);\n\n      // Both keys should be accessible\n      const result1 = await findApiKey(testApiKey.key);\n      expect(result1).not.toBeNull();\n\n      const result2 = await findApiKey(key2.key);\n      expect(result2).not.toBeNull();\n\n      // These should be cache hits (warm-up pre-loaded them)\n      const stats = apiKeyCache.getStats();\n      expect(stats.hits).toBe(2);\n      expect(stats.misses).toBe(0);\n    });\n\n    it('should handle warm-up when cache is already populated', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Pre-populate cache with one key\n      await findApiKey(testApiKey.key);\n      const initialSize = apiKeyCache.size;\n\n      // Run warm-up (should add the same key again, updating it)\n      await warmupCache();\n\n      // Cache should still have the key\n      expect(apiKeyCache.size).toBe(initialSize);\n\n      // Key should still be accessible\n      const result = await findApiKey(testApiKey.key);\n      expect(result).not.toBeNull();\n    });\n  });\n\n  describe('Negative caching edge cases', () => {\n    it('should cache not-found keys to prevent repeated lookups', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Clear cache completely and reset stats\n      apiKeyCache.clear();\n      apiKeyCache.resetStats();\n\n      // Verify cache is truly empty\n      expect(apiKeyCache.size).toBe(0);\n      expect(apiKeyCache.getStats().misses).toBe(0);\n\n      // Request non-existent key (should be a cache miss and populate negative cache)\n      const result1 = await findApiKey('pk_does_not_exist');\n      expect(result1).toBeNull();\n\n      // After first call, we should have the negative entry cached\n      expect(apiKeyCache.has('pk_does_not_exist')).toBe(true);\n\n      // The stats should have been updated (either miss or hit depending on implementation)\n      const stats1 = apiKeyCache.getStats();\n\n      // Request same non-existent key again (should be a cache hit from negative cache)\n      const result2 = await findApiKey('pk_does_not_exist');\n      expect(result2).toBeNull();\n\n      // Should have at least 1 hit (from negative cache)\n      const stats2 = apiKeyCache.getStats();\n      expect(stats2.hits).toBeGreaterThanOrEqual(1);\n\n      // Verify the null is still cached\n      expect(apiKeyCache.has('pk_does_not_exist')).toBe(true);\n      expect(apiKeyCache.get('pk_does_not_exist')).toBeNull();\n    });\n\n    it('should invalidate negative cache when key is added', async () => {\n      await writeApiKeys({ keys: [] });\n\n      // Request non-existent key (caches null)\n      const result1 = await findApiKey('pk_new_key');\n      expect(result1).toBeNull();\n      expect(apiKeyCache.has('pk_new_key')).toBe(true);\n\n      // Add the key to file\n      const newKey = {\n        ...testApiKey,\n        key: 'pk_new_key',\n      };\n      await writeApiKeys({ keys: [newKey] });\n\n      // Clear cache entry to simulate key being added externally\n      apiKeyCache.delete('pk_new_key');\n\n      // Now request should find the key\n      const result2 = await findApiKey('pk_new_key');\n      expect(result2).not.toBeNull();\n      expect(result2?.key).toBe('pk_new_key');\n\n      // Positive result should now be cached\n      expect(apiKeyCache.get('pk_new_key')).not.toBeNull();\n    });\n  });\n\n  describe('Cache statistics accuracy', () => {\n    it('should accurately track hits and misses', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      // Clear stats\n      apiKeyCache.clear();\n      apiKeyCache.resetStats();\n\n      // Populate cache\n      await findApiKey(testApiKey.key);\n      await findApiKey('pk_nonexistent');\n\n      // Reset stats to start counting from here\n      apiKeyCache.resetStats();\n\n      // Hit - from cache (testApiKey)\n      await findApiKey(testApiKey.key);\n\n      // Hit - from negative cache (pk_nonexistent)\n      await findApiKey('pk_nonexistent');\n\n      const stats = apiKeyCache.getStats();\n      expect(stats.hits).toBe(2);\n      expect(stats.misses).toBe(0);\n      expect(stats.hitRate).toBe(100);\n    });\n\n    it('should calculate hit rate correctly', async () => {\n      await writeApiKeys({ keys: [testApiKey] });\n\n      apiKeyCache.clear();\n      apiKeyCache.resetStats();\n\n      // First call populates cache (1 miss)\n      await findApiKey(testApiKey.key);\n\n      // Reset stats to measure only hits\n      apiKeyCache.resetStats();\n\n      // 10 hits from cache\n      for (let i = 0; i < 10; i++) {\n        await findApiKey(testApiKey.key);\n      }\n\n      const stats = apiKeyCache.getStats();\n      expect(stats.hits).toBe(10);\n      expect(stats.misses).toBe(0);\n      expect(stats.hitRate).toBe(100);\n    });\n  });\n});\n",
        "last_modified": "2026-01-22T13:20:55.583726"
      },
      "task_intent": {
        "title": "Implement in-memory API key cache with TTL to eliminate file I/O on every request",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-22T12:46:07.684991",
  "last_updated": "2026-01-22T13:20:55.492572"
}